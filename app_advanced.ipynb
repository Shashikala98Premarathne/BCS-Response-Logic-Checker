{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceacd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(page_title=\"Consistency Checker â€” Advanced\", layout=\"wide\")\n",
    "st.title(\"ðŸ“Š Questionnaire Logic Checker â€” Advanced Addâ€‘on\")\n",
    "st.caption(\"Brand-pattern rules, cross-wave checks, and client sample validations.\")\n",
    "\n",
    "# =============================\n",
    "# Base uploads\n",
    "# =============================\n",
    "with st.sidebar:\n",
    "    st.header(\"Inputs\")\n",
    "    uploaded_file = st.file_uploader(\"Current wave data (CSV)\", type=[\"csv\"], key=\"this\")\n",
    "    client_sample_file = st.file_uploader(\"Client sample (CSV)\", type=[\"csv\"], key=\"client\")\n",
    "    last_wave_file = st.file_uploader(\"Last wave data (CSV)\", type=[\"csv\"], key=\"prev\")\n",
    "    desk_research_file = st.file_uploader(\"Desk research (CSV)\", type=[\"csv\"], key=\"desk\")\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Thresholds\")\n",
    "    main_cap = st.slider(\"A1a brand count cap\", 3, 20, 8)\n",
    "    close_min = st.slider(\"C-close expected minimum when strong intent\", 5, 10, 8)\n",
    "\n",
    "if not uploaded_file:\n",
    "    st.info(\"Upload your current wave CSV to start.\")\n",
    "    st.stop()\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "except Exception as e:\n",
    "    st.error(f\"Failed to read current wave CSV: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "client_df = pd.read_csv(client_sample_file) if client_sample_file else None\n",
    "last_wave_df = pd.read_csv(last_wave_file) if last_wave_file else None\n",
    "desk_df = pd.read_csv(desk_research_file) if desk_research_file else None\n",
    "\n",
    "# Result frame\n",
    "result = df.copy()\n",
    "\n",
    "# Helpers\n",
    "\n",
    "def ensure_in_list(val, allowed: List[int]) -> bool:\n",
    "    try:\n",
    "        vi = int(float(val))\n",
    "        return vi in allowed\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def boolish(val) -> bool:\n",
    "    s = str(val).strip().lower()\n",
    "    return s in {\"1\", \"true\", \"yes\", \"y\", \"t\"} or ensure_in_list(val, [1])\n",
    "\n",
    "\n",
    "def find_brand_columns(frame: pd.DataFrame, prefix: str) -> Dict[str, str]:\n",
    "    pat = re.compile(r\"^\" + re.escape(prefix) + r\"[_\\- ]?(?P<brand>.+)$\", re.IGNORECASE)\n",
    "    out: Dict[str, str] = {}\n",
    "    for c in frame.columns:\n",
    "        m = pat.match(c)\n",
    "        if m:\n",
    "            out[m.group(\"brand\")] = c\n",
    "    return out\n",
    "\n",
    "# 1) S2 vs S3\n",
    "if \"S2\" in df.columns and \"S3\" in df.columns:\n",
    "    mis = df[\"S2\"].astype(str) != df[\"S3\"].astype(str)\n",
    "    result.loc[mis, \"CHK_S2_vs_S3\"] = \"Mismatch\"\n",
    "    result.loc[~mis, \"CHK_S2_vs_S3\"] = \"OK\"\n",
    "\n",
    "# 2) S4a1 vs client sample year\n",
    "if client_df is not None and \"S4a1\" in df.columns:\n",
    "    id_col = next((c for c in [\"ID\", \"RespondentID\", \"RID\", \"id\"] if c in df.columns and c in client_df.columns), None)\n",
    "    year_col = next((c for c in client_df.columns if re.search(r\"year\", c, re.IGNORECASE)), None)\n",
    "    if id_col and year_col:\n",
    "        merged = df[[id_col, \"S4a1\"]].merge(client_df[[id_col, year_col]], on=id_col, how=\"left\")\n",
    "        y1 = merged[\"S4a1\"].astype(str).str.extract(r\"(\\d{4})\")[0]\n",
    "        y2 = merged[year_col].astype(str).str.extract(r\"(\\d{4})\")[0]\n",
    "        mis_ids = merged.loc[y1 != y2, id_col]\n",
    "        result.loc[result[id_col].isin(mis_ids), \"CHK_S4a1_vs_ClientYear\"] = \"Mismatch\"\n",
    "        result[\"CHK_S4a1_vs_ClientYear\"] = result[\"CHK_S4a1_vs_ClientYear\"].fillna(\"OK\")\n",
    "\n",
    "# 3) A1a total sanity and cap vs S3\n",
    "a1a_cols = [c for c in df.columns if c.lower().startswith(\"a1a_\")]\n",
    "if a1a_cols:\n",
    "    sel = df[a1a_cols].applymap(boolish)\n",
    "    counts = sel.sum(axis=1)\n",
    "    result[\"CHK_A1a_total_count\"] = counts\n",
    "    result.loc[counts > main_cap, \"CHK_A1a_total_flag\"] = f\">{main_cap} brands\"\n",
    "    result.loc[counts <= main_cap, \"CHK_A1a_total_flag\"] = \"OK\"\n",
    "    if \"S3\" in df.columns:\n",
    "        s3n = pd.to_numeric(df[\"S3\"], errors=\"coerce\")\n",
    "        result.loc[(s3n.notna()) & (counts < s3n), \"CHK_A1a_vs_S3\"] = \"A1a < S3\"\n",
    "        result.loc[(s3n.notna()) & (counts >= s3n), \"CHK_A1a_vs_S3\"] = result.loc[(s3n.notna()) & (counts >= s3n), \"CHK_A1a_vs_S3\"].fillna(\"OK\")\n",
    "\n",
    "# 4) A2b main make âˆˆ A1a\n",
    "a2b_col = next((c for c in df.columns if c.lower().startswith(\"a2b\")), None)\n",
    "if a2b_col and a1a_cols:\n",
    "    def a2b_in_a1a(row) -> bool:\n",
    "        brand = str(row[a2b_col]).strip()\n",
    "        if not brand or brand.lower() == \"nan\":\n",
    "            return True\n",
    "        matches = [c for c in a1a_cols if c.split(\"_\", 1)[-1].strip().lower() == brand.lower()]\n",
    "        if not matches:\n",
    "            return False\n",
    "        return any(boolish(row[m]) for m in matches)\n",
    "    ok = df.apply(a2b_in_a1a, axis=1)\n",
    "    result.loc[~ok, \"CHK_A2b_in_A1a\"] = \"Main make not in A1a\"\n",
    "    result[\"CHK_A2b_in_A1a\"] = result[\"CHK_A2b_in_A1a\"].fillna(\"OK\")\n",
    "\n",
    "# 5 & 16) S4a1 year âˆˆ A3 years\n",
    "a3_cols = [c for c in df.columns if c.lower().startswith(\"a3\")]\n",
    "if \"S4a1\" in df.columns and a3_cols:\n",
    "    def a3_has_year(row) -> bool:\n",
    "        txt = str(row[\"S4a1\"]) if pd.notna(row[\"S4a1\"]) else \"\"\n",
    "        m = re.search(r\"(\\d{4})\", txt)\n",
    "        if not m:\n",
    "            return True\n",
    "        y = m.group(1)\n",
    "        for c in a3_cols:\n",
    "            if y in str(row[c]):\n",
    "                return True\n",
    "        return False\n",
    "    ok = df.apply(a3_has_year, axis=1)\n",
    "    result.loc[~ok, \"CHK_S4a1_vs_A3\"] = \"Year not listed in A3\"\n",
    "    result[\"CHK_S4a1_vs_A3\"] = result[\"CHK_S4a1_vs_A3\"].fillna(\"OK\")\n",
    "\n",
    "# 7) B1 vs A2a (used brands must have B1 âˆˆ {4,5})\n",
    "b1_map = find_brand_columns(df, \"B1\")\n",
    "a2a_map = find_brand_columns(df, \"A2a\")\n",
    "for brand, a2a_c in a2a_map.items():\n",
    "    b1_c = b1_map.get(brand)\n",
    "    if not b1_c:\n",
    "        continue\n",
    "    used = df[a2a_c].apply(boolish)\n",
    "    bad = used & ~df[b1_c].apply(lambda x: ensure_in_list(x, [4, 5]))\n",
    "    result.loc[bad, f\"CHK_B1_for_used_{brand}\"] = \"B1 should be 4/5\"\n",
    "\n",
    "# 8) B2 vs B3a (consider â†’ good impression 4/5)\n",
    "b2_map = find_brand_columns(df, \"B2\")\n",
    "b3a_map = find_brand_columns(df, \"B3a\")\n",
    "for brand, b3a_c in b3a_map.items():\n",
    "    b2_c = b2_map.get(brand)\n",
    "    if not b2_c:\n",
    "        continue\n",
    "    cons = df[b3a_c].apply(boolish)\n",
    "    bad = cons & ~df[b2_c].apply(lambda x: ensure_in_list(x, [4, 5]))\n",
    "    result.loc[bad, f\"CHK_B2_for_consider_{brand}\"] = \"B2 should be 4/5\"\n",
    "\n",
    "# 9) B3b mentioned â†’ B2 4/5\n",
    "b3b_map = find_brand_columns(df, \"B3b\")\n",
    "for brand, b3b_c in b3b_map.items():\n",
    "    b2_c = b2_map.get(brand)\n",
    "    if not b2_c:\n",
    "        continue\n",
    "    mentioned = df[b3b_c].apply(boolish)\n",
    "    bad = mentioned & ~df[b2_c].apply(lambda x: ensure_in_list(x, [4, 5]))\n",
    "    result.loc[bad, f\"CHK_B2_for_B3b_{brand}\"] = \"B2 should be 4/5\"\n",
    "\n",
    "# 10) C-close vs B3b/B3a/B2 (expect >= close_min)\n",
    "cclose_map = find_brand_columns(df, \"Cclose\") or find_brand_columns(df, \"C_close\")\n",
    "for brand, c_c in cclose_map.items():\n",
    "    strong = pd.Series(False, index=df.index)\n",
    "    if brand in b3b_map:\n",
    "        strong |= df[b3b_map[brand]].apply(boolish)\n",
    "    if brand in b3a_map:\n",
    "        strong |= df[b3a_map[brand]].apply(boolish)\n",
    "    if brand in b2_map:\n",
    "        strong |= df[b2_map[brand]].apply(lambda x: ensure_in_list(x, [4, 5]))\n",
    "    bad = strong & ~df[c_c].apply(lambda x: ensure_in_list(x, list(range(close_min, 11))))\n",
    "    result.loc[bad, f\"CHK_Cclose_high_{brand}\"] = f\"Expect â‰¥{close_min}\"\n",
    "\n",
    "# 11) Cfunc vs B2 (monotonic alignment)\n",
    "cfunc_map = find_brand_columns(df, \"Cfunc\")\n",
    "for brand, cf_c in cfunc_map.items():\n",
    "    b2_c = b2_map.get(brand)\n",
    "    if not b2_c:\n",
    "        continue\n",
    "    def misaligned(r):\n",
    "        b2v = pd.to_numeric(r[b2_c], errors=\"coerce\")\n",
    "        cfv = pd.to_numeric(r[cf_c], errors=\"coerce\")\n",
    "        if pd.isna(b2v) or pd.isna(cfv):\n",
    "            return False\n",
    "        return (b2v < 4) and (cfv >= 4)\n",
    "    bad = df.apply(misaligned, axis=1)\n",
    "    result.loc[bad, f\"CHK_Cfunc_vs_B2_{brand}\"] = \"Misaligned\"\n",
    "\n",
    "# 12) G2 vs G1 (industry-based rule; example for Mining)\n",
    "if \"G1\" in df.columns and \"G2\" in df.columns:\n",
    "    def g_rule(row):\n",
    "        industry = str(row[\"G1\"]).strip().lower()\n",
    "        try:\n",
    "            dist = float(row[\"G2\"])  # km\n",
    "        except Exception:\n",
    "            return True\n",
    "        if \"mining\" in industry:\n",
    "            return dist <= 50\n",
    "        return True\n",
    "    ok = df.apply(g_rule, axis=1)\n",
    "    result.loc[~ok, \"CHK_G2_vs_G1\"] = \"Range not plausible for industry\"\n",
    "\n",
    "# 23) Straight-liners in F2/F4/F6\n",
    "for blk in [\"F2\", \"F4\", \"F6\"]:\n",
    "    blk_cols = [c for c in df.columns if c.lower().startswith(blk.lower() + \"_\")]\n",
    "    if blk_cols:\n",
    "        vals = df[blk_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        straight = vals.nunique(axis=1) == 1\n",
    "        result.loc[straight, f\"CHK_{blk}_straightliner\"] = \"Straight-liner\"\n",
    "\n",
    "# 24) B3a vs E4 (consider â†’ probably/definitely)\n",
    "e4_map = find_brand_columns(df, \"E4\")\n",
    "for brand, b3a_c in b3a_map.items():\n",
    "    e4_c = e4_map.get(brand)\n",
    "    if not e4_c:\n",
    "        continue\n",
    "    sel = df[b3a_c].apply(boolish)\n",
    "    bad = sel & ~df[e4_c].apply(lambda x: ensure_in_list(x, [4, 5]))\n",
    "    result.loc[bad, f\"CHK_E4_for_B3a_{brand}\"] = \"E4 should be 4/5\"\n",
    "\n",
    "# 25) E1/E4/E4c vs B2 (positive B2 â†’ higher E*)\n",
    "e1_map = find_brand_columns(df, \"E1\")\n",
    "e4c_map = find_brand_columns(df, \"E4c\")\n",
    "for brand, b2_c in b2_map.items():\n",
    "    pos = df[b2_c].apply(lambda x: ensure_in_list(x, [4, 5]))\n",
    "    for lab, m in [(\"E1\", e1_map), (\"E4\", e4_map), (\"E4c\", e4c_map)]:\n",
    "        if m and brand in m:\n",
    "            bad = pos & ~df[m[brand]].apply(lambda x: ensure_in_list(x, [4, 5]))\n",
    "            result.loc[bad, f\"CHK_{lab}_for_posB2_{brand}\"] = f\"{lab} should be 4/5\"\n",
    "\n",
    "# 31, 33, 34) Combined intent consistency\n",
    "for brand in set(b3a_map) & set(b2_map) & set(cclose_map):\n",
    "    sel = df[b3a_map[brand]].apply(boolish)\n",
    "    b2_hi = df[b2_map[brand]].apply(lambda x: ensure_in_list(x, [5]))\n",
    "    b2_low = df[b2_map[brand]].apply(lambda x: ensure_in_list(x, [1, 2, 3]))\n",
    "    c_hi = df[cclose_map[brand]].apply(lambda x: ensure_in_list(x, list(range(close_min, 11))))\n",
    "    result.loc[sel & b2_low, f\"CHK_B2_low_with_B3a_{brand}\"] = \"Conflict\"\n",
    "    result.loc[sel & b2_hi & ~c_hi, f\"CHK_Cclose_low_with_hiB2_{brand}\"] = f\"Expect â‰¥{close_min}\"\n",
    "\n",
    "# 37) E1 vs F1 proximity\n",
    "if \"E1\" in df.columns and \"F1\" in df.columns:\n",
    "    e1 = pd.to_numeric(df[\"E1\"], errors=\"coerce\")\n",
    "    f1 = pd.to_numeric(df[\"F1\"], errors=\"coerce\")\n",
    "    result.loc[(e1 - f1).abs() > 2, \"CHK_E1_vs_F1\"] = \">2 pts diff\"\n",
    "    result[\"CHK_E1_vs_F1\"] = result[\"CHK_E1_vs_F1\"].fillna(\"OK\")\n",
    "\n",
    "# Cross-wave summaries (14, 15, 17, 35, 36) â€” quick metrics\n",
    "notes = []\n",
    "if last_wave_df is not None:\n",
    "    a1a_map_now = find_brand_columns(df, \"A1a\")\n",
    "    a2a_map_now = find_brand_columns(df, \"A2a\")\n",
    "    if a1a_map_now and a2a_map_now:\n",
    "        this_rates = []\n",
    "        for b, a2 in a2a_map_now.items():\n",
    "            a1 = a1a_map_now.get(b)\n",
    "            if not a1:\n",
    "                continue\n",
    "            r = ((~df[a1].apply(boolish)) & df[a2].apply(boolish)).mean()\n",
    "            this_rates.append(r)\n",
    "        if this_rates:\n",
    "            notes.append(f\"This wave A2a-not-in-A1a avg: {np.mean(this_rates):.1%}\")\n",
    "    a1a_map_prev = find_brand_columns(last_wave_df, \"A1a\")\n",
    "    a2a_map_prev = find_brand_columns(last_wave_df, \"A2a\")\n",
    "    prev_rates = []\n",
    "    for b, a2 in a2a_map_prev.items():\n",
    "        a1 = a1a_map_prev.get(b)\n",
    "        if not a1:\n",
    "            continue\n",
    "        r = ((~last_wave_df[a1].apply(boolish)) & last_wave_df[a2].apply(boolish)).mean()\n",
    "        prev_rates.append(r)\n",
    "    if prev_rates:\n",
    "        notes.append(f\"Last wave avg: {np.mean(prev_rates):.1%}\")\n",
    "\n",
    "if desk_df is not None:\n",
    "    notes.append(\"Desk research attached: use for availability/awareness plausibility checks.\")\n",
    "\n",
    "st.subheader(\"Results\")\n",
    "st.dataframe(result, use_container_width=True)\n",
    "\n",
    "csv = result.to_csv(index=False).encode(\"utf-8\")\n",
    "st.download_button(\"ðŸ’¾ Download checked CSV\", csv, file_name=\"checked_advanced.csv\", mime=\"text/csv\")\n",
    "\n",
    "if notes:\n",
    "    st.info(\"\\n\".join(notes))\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"**Notes:** This addâ€‘on implements a first pass of rules 1, 2, 3, 4, 5/16, 7, 8, 9, 10, 11, 12, 23, 24, 25, 31/33/34, and 37. Others require custom mappings or manual recode inputs (industry/region recodes, openâ€‘end cleaning, desk research comparisons, Volvo/BCS specifics). Upload lastâ€‘wave and client sample files to enable the related checks.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c739789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCS Survey Logic Checker â€” Lite (clean, rulesâ€‘json)\n",
    "# Streamlit app that runs row-level logic checks using your column schema only.\n",
    "# Excludes last-wave, client-sample, and desk-research inputs & checks.\n",
    "\n",
    "import re\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import json\n",
    "\n",
    "st.set_page_config(page_title=\"BCS Survey Logic Checker â€” Lite\", layout=\"wide\")\n",
    "st.title(\"ðŸ“Š BCS Survey Logic Checker â€” Lite\")\n",
    "st.caption(\"No cross-wave / client-sample / desk-research dependencies. Uses your schema and brand patterns. Optional custom rules JSON.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Upload\n",
    "# ----------------------------\n",
    "with st.sidebar:\n",
    "    st.header(\"Input\")\n",
    "    data_file = st.file_uploader(\"Current wave data (CSV)\", type=[\"csv\"]) \n",
    "    rules_file = st.file_uploader(\"Optional: custom rules JSON\", type=[\"json\"]) \n",
    "    rules = json.load(rules_file) if rules_file else None\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Thresholds\")\n",
    "    a1a_cap = st.slider(\"Max #brands in unaided awareness (A1a)\", 3, 25, 8)\n",
    "    close_min = st.slider(\"C-close minimum when intent is strong\", 5, 10, 8)\n",
    "    cfunc_hi = st.slider(\"Cfunc (performance) 'high' threshold when B2 is low\", 4, 10, 6)\n",
    "\n",
    "if not data_file:\n",
    "    st.info(\"Upload the current wave CSV to begin.\")\n",
    "    st.stop()\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "except Exception as e:\n",
    "    st.error(f\"Failed to read CSV: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "res = df.copy()\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers & mappings (from your schema)\n",
    "# ----------------------------\n",
    "# Brand blocks\n",
    "PREFIX = {\n",
    "    \"awareness\": \"unaided_aware_\",      # A1a multi (0/1)\n",
    "    \"usage\": \"usage_\",                  # A2a multi (0/1)\n",
    "    \"impression\": \"overall_impression_\",# B2 1â€“5\n",
    "    \"consider\": \"consideration_\",       # B3a multi (0/1)\n",
    "    \"close\": \"closeness_\",              # C-close 1â€“10\n",
    "    \"cfunc\": \"performance_\",            # Cfunc 1â€“10 in this study\n",
    "}\n",
    "\n",
    "# Single-select brand fields\n",
    "COL = {\n",
    "    \"main_brand\": \"main_brand\",                 # A2b (preferred of A2a)\n",
    "    \"pref_future_single\": \"preference\",         # B3b single pick (brand code or label)\n",
    "    \"E1_overall\": \"overall_satisfaction\",      # E1 (1â€“5)\n",
    "    \"E4_choose_brand\": \"likelihood_choose_brand\",  # E4 (1â€“5)\n",
    "}\n",
    "\n",
    "# Overall / screening\n",
    "S = {\n",
    "    \"HD_count\": \"n_heavy_duty_trucks\",   # S3\n",
    "    \"Tractors\": \"n_tractors\",            # S3a1 (Korea only)\n",
    "    \"Rigids\": \"n_rigids\",                # S3a2 (Korea only)\n",
    "    \"Tippers\": \"n_tippers\",              # S3a3 (Korea only)\n",
    "    \"LastPurchaseHD_cat\": \"last_purchase_hdt\",   # S4a1 coded 1..9\n",
    "}\n",
    "\n",
    "# Brand name â†” code map (MASTER BRAND LIST)\n",
    "BRAND_NAME_TO_CODE = {\n",
    "    \"ashok leyland\": \"1\", \"asia motor works\": \"2\", \"beijing auto/baic/beiqi futian\": \"3\", \"chevrolet\": \"4\",\n",
    "    \"cnhtc/steyr\": \"5\", \"tata / tata daewoo\": \"6\", \"daf\": \"7\", \"dongfeng\": \"8\", \"eicher\": \"9\",\n",
    "    \"erf\": \"10\", \"foden\": \"11\", \"force motors\": \"12\", \"ford\": \"13\", \"freightliner\": \"14\", \"hino\": \"15\",\n",
    "    \"hongyan/sichuan auto/saic\": \"16\", \"hyundai\": \"17\", \"international\": \"18\", \"isuzu\": \"19\", \"iveco\": \"20\",\n",
    "    \"jie fang/faw\": \"21\", \"kenworth\": \"22\", \"mack\": \"23\", \"mahindra\": \"24\", \"man\": \"25\",\n",
    "    \"mercedes benz\": \"26\", \"fuso\": \"27\", \"ud trucks\": \"28\", \"norinco\": \"29\", \"peterbilt\": \"30\",\n",
    "    \"renault trucks\": \"31\", \"scania\": \"32\", \"sterling\": \"33\", \"tata motors\": \"34\", \"tatra\": \"35\",\n",
    "    \"western star\": \"36\", \"volkswagen\": \"37\", \"volvo\": \"38\", \"yan an/shaanxi auto\": \"39\",\n",
    "    \"swaraj mazda limited\": \"40\", \"bharat benz\": \"41\", \"nissan diesel\": \"42\", \"cat\": \"43\",\n",
    "    \"dennis eagle\": \"44\", \"jac\": \"45\", \"camc\": \"46\", \"foton\": \"47\", \"sinotruck / sitrak\": \"48\",\n",
    "    \"sany\": \"49\", \"shacman\": \"50\", \"powerland\": \"51\", \"powerstar\": \"52\", \"howo\": \"53\", \"hitachi\": \"54\",\n",
    "    \"quester\": \"55\", \"lgmg\": \"56\", \"liugong\": \"57\", \"other\": \"98\",\n",
    "}\n",
    "\n",
    "BRAND_SUFFIX_RE = re.compile(r\"_b(?P<brand>\\d+)$\", re.IGNORECASE)\n",
    "\n",
    "# Discover brands present for each block\n",
    "brand_cols: Dict[str, Dict[str, str]] = {blk: {} for blk in PREFIX}\n",
    "for c in df.columns:\n",
    "    for blk, pre in PREFIX.items():\n",
    "        if c.startswith(pre):\n",
    "            m = BRAND_SUFFIX_RE.search(c)\n",
    "            if m:\n",
    "                brand_cols[blk][m.group(\"brand\")] = c\n",
    "\n",
    "brands: Set[str] = set().union(*[set(d.keys()) for d in brand_cols.values()])\n",
    "getb = lambda mapping, b: mapping.get(str(b))\n",
    "\n",
    "# helpers\n",
    "\n",
    "def to_num(x):\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def boolish(x) -> bool:\n",
    "    s = str(x).strip().lower()\n",
    "    return s in {\"1\", \"true\", \"t\", \"yes\", \"y\"}\n",
    "\n",
    "\n",
    "def in_vals(x, allowed: List[int]) -> bool:\n",
    "    try:\n",
    "        return int(float(x)) in allowed\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def parse_brand_id(val) -> str | None:\n",
    "    \"\"\"Return brand code as string (e.g., '38') from code like 38 / 'b38',\n",
    "    or from label names using BRAND_NAME_TO_CODE (case-insensitive).\"\"\"\n",
    "    s = str(val).strip()\n",
    "    if not s or s.lower() in {\"nan\", \"none\"}:\n",
    "        return None\n",
    "    if s.isdigit():\n",
    "        return s\n",
    "    sl = s.lower()\n",
    "    m = re.search(r\"b(\\d+)$\", sl)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    if sl in BRAND_NAME_TO_CODE:\n",
    "        return BRAND_NAME_TO_CODE[sl]\n",
    "    sl2 = re.sub(r\"\\s+\", \" \", sl.replace(\"-\", \" \").replace(\"/\", \"/\"))\n",
    "    return BRAND_NAME_TO_CODE.get(sl2)\n",
    "\n",
    "# ----- Optional custom rules JSON (from Rule Builder) -----\n",
    "\n",
    "def apply_custom_rules(df: pd.DataFrame, res: pd.DataFrame, rules: dict | None) -> pd.DataFrame:\n",
    "    \"\"\"Apply generic custom rules exported from Rule Builder to augment built-in checks.\n",
    "    Supported types:\n",
    "      - equals: {\"cols\":[\"A\",\"B\"]}\n",
    "      - implies_values: if Xâˆˆ{â€¦} â‡’ Yâˆˆ{â€¦}\n",
    "      - brand_consider_implies_impression: auto-iterate across brand ids for prefixes\n",
    "    \"\"\"\n",
    "    if not rules:\n",
    "        return res\n",
    "    for r in rules.get(\"rules\", []):\n",
    "        t = r.get(\"type\")\n",
    "        name = r.get(\"name\") or f\"CHK_{t}\"\n",
    "        msg = r.get(\"message\", \"Violation\")\n",
    "\n",
    "        if t == \"equals\":\n",
    "            a, b = r.get(\"cols\", [None, None])\n",
    "            if a in df.columns and b in df.columns:\n",
    "                bad = df[a].astype(str) != df[b].astype(str)\n",
    "                res[name] = \"OK\"\n",
    "                res.loc[bad, name] = msg\n",
    "\n",
    "        elif t == \"implies_values\":\n",
    "            cond_col = r.get(\"if\", {}).get(\"col\")\n",
    "            then_col = r.get(\"then\", {}).get(\"col\")\n",
    "            cond_vals = r.get(\"if\", {}).get(\"in\", [])\n",
    "            allow_vals = r.get(\"then\", {}).get(\"allowed\", [])\n",
    "            if cond_col in df.columns and then_col in df.columns:\n",
    "                cond = df[cond_col].isin(cond_vals)\n",
    "                bad = cond & ~df[then_col].isin(allow_vals)\n",
    "                res[name] = np.where(cond, \"OK\", res.get(name, \"\")).astype(str)\n",
    "                res.loc[bad, name] = msg\n",
    "\n",
    "        elif t == \"brand_consider_implies_impression\":\n",
    "            consider_prefix = r.get(\"consider_prefix\", \"consideration_\")\n",
    "            impression_prefix = r.get(\"impression_prefix\", \"overall_impression_\")\n",
    "            allowed = r.get(\"allowed\", [4, 5])\n",
    "            for col in df.columns:\n",
    "                if not col.startswith(consider_prefix):\n",
    "                    continue\n",
    "                m = re.search(r\"_b(\\d+)$\", col)\n",
    "                if not m:\n",
    "                    continue\n",
    "                bid = m.group(1)\n",
    "                tgt = f\"{impression_prefix}b{bid}\"\n",
    "                if tgt not in df.columns:\n",
    "                    continue\n",
    "                name_bid = f\"{name}_b{bid}\"\n",
    "                bad = (to_num(df[col]) == 1) & ~to_num(df[tgt]).isin(allowed)\n",
    "                res[name_bid] = \"OK\"\n",
    "                res.loc[bad, name_bid] = msg\n",
    "    return res\n",
    "\n",
    "# ----------------------------\n",
    "# Checks (Lite set)\n",
    "# ----------------------------\n",
    "# 0) Structural: S3a1-3 sum equals S3 (if all exist)\n",
    "if all(k in df.columns for k in [S[\"HD_count\"], S[\"Tractors\"], S[\"Rigids\"], S[\"Tippers\"]]):\n",
    "    res[\"CHK_S3a_sum\"] = \"OK\"\n",
    "    subsum = to_num(df[S[\"Tractors\"]]).fillna(0) + to_num(df[S[\"Rigids\"]]).fillna(0) + to_num(df[S[\"Tippers\"]]).fillna(0)\n",
    "    total = to_num(df[S[\"HD_count\"]])\n",
    "    res.loc[(total.notna()) & (subsum != total), \"CHK_S3a_sum\"] = \"S3a1-3 â‰  S3\"\n",
    "\n",
    "# 3) A1a total sanity (awareness) + cap\n",
    "aw_cols = list(brand_cols[\"awareness\"].values())\n",
    "if aw_cols:\n",
    "    sel_aw = df[aw_cols].applymap(boolish)\n",
    "    count_aw = sel_aw.sum(axis=1)\n",
    "    res[\"CHK_A1a_total_count\"] = count_aw\n",
    "    res[\"CHK_A1a_total_flag\"] = np.where(count_aw > a1a_cap, f\">{a1a_cap} brands\", \"OK\")\n",
    "\n",
    "# 4) Main make (A2b) must be in A1a and A2a\n",
    "if COL[\"main_brand\"] in df.columns:\n",
    "    res[\"CHK_A2b_in_A1a\"] = \"OK\"\n",
    "    res[\"CHK_A2b_in_A2a\"] = \"OK\"\n",
    "    mb = df[COL[\"main_brand\"]].apply(parse_brand_id)\n",
    "    for i, b in mb.items():\n",
    "        if b is None:\n",
    "            continue\n",
    "        a1col = getb(brand_cols[\"awareness\"], b)\n",
    "        ucol = getb(brand_cols[\"usage\"], b)\n",
    "        if a1col is not None and not boolish(df.at[i, a1col]):\n",
    "            res.loc[i, \"CHK_A2b_in_A1a\"] = \"Main brand not in A1a\"\n",
    "        if ucol is not None and not boolish(df.at[i, ucol]):\n",
    "            res.loc[i, \"CHK_A2b_in_A2a\"] = \"Main brand not in A2a\"\n",
    "\n",
    "# 7) If a brand is used (A2a), B2 overall impression should be 4/5\n",
    "if brand_cols[\"usage\"] and brand_cols[\"impression\"]:\n",
    "    for b in brands:\n",
    "        ucol = getb(brand_cols[\"usage\"], b)\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not ucol or not icol:\n",
    "            continue\n",
    "        used = df[ucol].apply(boolish)\n",
    "        bad = used & ~df[icol].apply(lambda x: in_vals(x, [4, 5]))\n",
    "        name = f\"CHK_B2_for_used_b{b}\"\n",
    "        res[name] = \"OK\"\n",
    "        res.loc[bad, name] = \"B2 should be 4/5\"\n",
    "\n",
    "# 8) If considering (B3a), B2 should be 4/5\n",
    "if brand_cols[\"consider\"] and brand_cols[\"impression\"]:\n",
    "    for b in brands:\n",
    "        ccol = getb(brand_cols[\"consider\"], b)\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not ccol or not icol:\n",
    "            continue\n",
    "        cons = df[ccol].apply(boolish)\n",
    "        bad = cons & ~df[icol].apply(lambda x: in_vals(x, [4, 5]))\n",
    "        name = f\"CHK_B2_for_consider_b{b}\"\n",
    "        res[name] = \"OK\"\n",
    "        res.loc[bad, name] = \"B2 should be 4/5\"\n",
    "\n",
    "# 9) If preferred for next purchase (B3b single), B2 for that brand should be 4/5\n",
    "if COL[\"pref_future_single\"] in df.columns and brand_cols[\"impression\"]:\n",
    "    pref = df[COL[\"pref_future_single\"]].apply(parse_brand_id)\n",
    "    for idx, b in pref.items():\n",
    "        if b is None:\n",
    "            continue\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not icol:\n",
    "            continue\n",
    "        name = f\"CHK_B2_for_pref_b{b}\"\n",
    "        res[name] = res.get(name, \"OK\")\n",
    "        if not in_vals(df.at[idx, icol], [4, 5]):\n",
    "            res.loc[idx, name] = \"B2 should be 4/5 for preferred brand\"\n",
    "\n",
    "# 10) C-close high when strong intent/impression\n",
    "if brand_cols[\"close\"]:\n",
    "    for b in brands:\n",
    "        ccol = getb(brand_cols[\"close\"], b)\n",
    "        if not ccol:\n",
    "            continue\n",
    "        strong = pd.Series(False, index=df.index)\n",
    "        if brand_cols[\"consider\"].get(b):\n",
    "            strong |= df[brand_cols[\"consider\"][b]].apply(boolish)\n",
    "        if brand_cols[\"impression\"].get(b):\n",
    "            strong |= df[brand_cols[\"impression\"][b]].apply(lambda x: in_vals(x, [4, 5]))\n",
    "        bad = strong & ~df[ccol].apply(lambda x: in_vals(x, list(range(close_min, 11))))\n",
    "        name = f\"CHK_Cclose_high_b{b}\"\n",
    "        res[name] = \"OK\"\n",
    "        res.loc[bad, name] = f\"Expect â‰¥{close_min}\"\n",
    "\n",
    "# 11) Cfunc vs B2 alignment (avoid high cfunc when B2 low)\n",
    "if brand_cols[\"cfunc\"] and brand_cols[\"impression\"]:\n",
    "    for b in brands:\n",
    "        cf = getb(brand_cols[\"cfunc\"], b)\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not cf or not icol:\n",
    "            continue\n",
    "        def misaligned(r):\n",
    "            b2v = to_num(r[icol])\n",
    "            cfv = to_num(r[cf])\n",
    "            if pd.isna(b2v) or pd.isna(cfv):\n",
    "                return False\n",
    "            return (b2v < 4) and (cfv >= cfunc_hi)\n",
    "        bad = df.apply(misaligned, axis=1)\n",
    "        name = f\"CHK_Cfunc_vs_B2_b{b}\"\n",
    "        res[name] = \"OK\"\n",
    "        res.loc[bad, name] = \"Misaligned\"\n",
    "\n",
    "# 23) Straight-liners: truck_rating_*, salesdelivery_rating_*, workshop_rating_*\n",
    "for pre in [\"truck_rating_\", \"salesdelivery_rating_\", \"workshop_rating_\"]:\n",
    "    cols = [c for c in df.columns if c.startswith(pre)]\n",
    "    if cols:\n",
    "        vals = df[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        straight = vals.nunique(axis=1) == 1\n",
    "        name = f\"CHK_{pre}straightliner\"\n",
    "        res[name] = \"OK\"\n",
    "        res.loc[straight, name] = \"Straight-liner\"\n",
    "\n",
    "# 24) If any brand considered but E4 low â†’ flag (coarse sanity, E4 is quota-make specific)\n",
    "if COL[\"E4_choose_brand\"] in df.columns and brand_cols[\"consider\"]:\n",
    "    low_e4 = ~df[COL[\"E4_choose_brand\"]].apply(lambda x: in_vals(x, [4, 5]))\n",
    "    any_consider = pd.DataFrame({b: df[col].apply(boolish) for b, col in brand_cols[\"consider\"].items()}).any(axis=1) if brand_cols[\"consider\"] else False\n",
    "    res[\"CHK_E4_low_with_consider\"] = \"OK\"\n",
    "    res.loc[any_consider & low_e4, \"CHK_E4_low_with_consider\"] = \"Low E4 but considering brands\"\n",
    "\n",
    "# 37) E1 vs F1 proximity (|diff|<=2)\n",
    "if COL[\"E1_overall\"] in df.columns and \"overall_rating_truck\" in df.columns:\n",
    "    e1 = to_num(df[COL[\"E1_overall\"]])\n",
    "    f1 = to_num(df[\"overall_rating_truck\"])\n",
    "    res[\"CHK_E1_vs_F1\"] = \"OK\"\n",
    "    res.loc[(e1 - f1).abs() > 2, \"CHK_E1_vs_F1\"] = \">2 pts diff\"\n",
    "\n",
    "# 5/16) S4a1 recent vs A3 (years-ago per brand): if S4a1 recent but no brand with â‰¤5 years\n",
    "A3_pre = \"last_purchase_b\"        # years ago (0..99 where 99=never)\n",
    "A4_pre = \"last_workshop_visit_b\"  # years ago (0..99/never)\n",
    "A4b_pre = \"last_workshop2_visit_b\"\n",
    "\n",
    "def find_yearago_block(prefix: str) -> Dict[str, str]:\n",
    "    m: Dict[str, str] = {}\n",
    "    for c in df.columns:\n",
    "        if c.startswith(prefix):\n",
    "            mm = BRAND_SUFFIX_RE.search(c)\n",
    "            if mm:\n",
    "                m[mm.group(\"brand\")] = c\n",
    "    return m\n",
    "\n",
    "A3 = find_yearago_block(A3_pre)\n",
    "A4 = find_yearago_block(A4_pre)\n",
    "A4b = find_yearago_block(A4b_pre)\n",
    "\n",
    "if S[\"LastPurchaseHD_cat\"] in df.columns and A3:\n",
    "    recent_hd = df[S[\"LastPurchaseHD_cat\"]].apply(lambda x: in_vals(x, [1,2,3,4,5,6]))\n",
    "    any_recent_brand = pd.DataFrame({b: to_num(df[c]) for b, c in A3.items()}) <= 5\n",
    "    has_recent = any_recent_brand.any(axis=1)\n",
    "    res[\"CHK_S4a1_vs_A3\"] = \"OK\"\n",
    "    res.loc[recent_hd & ~has_recent, \"CHK_S4a1_vs_A3\"] = \"No brand with purchase â‰¤5y despite S4a1 recent\"\n",
    "\n",
    "# Usage but never used authorised workshop (A4 = 99)\n",
    "if A4 and brand_cols[\"usage\"]:\n",
    "    for b in brands:\n",
    "        ucol = getb(brand_cols[\"usage\"], b)\n",
    "        wcol = A4.get(b)\n",
    "        if not ucol or not wcol:\n",
    "            continue\n",
    "        used = df[ucol].apply(boolish)\n",
    "        never_ws = to_num(df[wcol]) == 99\n",
    "        name = f\"CHK_A4_never_b{b}\"\n",
    "        res[name] = \"OK\"\n",
    "        res.loc[used & never_ws, name] = \"Used brand but never used workshop\"\n",
    "\n",
    "# ----------------------------\n",
    "# Apply optional custom rules JSON (if provided)\n",
    "# ----------------------------\n",
    "try:\n",
    "    res = apply_custom_rules(df, res, rules)\n",
    "except Exception:\n",
    "    st.warning(\"Custom rules JSON present but could not be applied. Check the Rule Builder export.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Output\n",
    "# ----------------------------\n",
    "st.subheader(\"Results preview\")\n",
    "st.dataframe(res, use_container_width=True)\n",
    "\n",
    "csv = res.to_csv(index=False).encode(\"utf-8\")\n",
    "st.download_button(\"ðŸ’¾ Download flagged CSV\", csv, file_name=\"bcs_checked_lite.csv\", mime=\"text/csv\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"**Included checks:** S3a sum to S3; A1a cap; A2bâˆˆA1a & âˆˆA2a; usage/considerâ†’B2â‰¥4; pref(B3b)â†’B2â‰¥4; strong intentâ†’C-closeâ‰¥min; Cfunc vs B2 (thresholded); straight-liners in F2/F4/F6; B3aÃ—E4 sanity; E1 vs F1 proximity; S4a1 recent vs A3 years-ago; usage but never workshop. **+ Optional custom rules JSON.**\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

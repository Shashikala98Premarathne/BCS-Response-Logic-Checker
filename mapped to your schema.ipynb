{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d737f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCS Survey Logic Checker â€” mapped to schema (clean, rulesâ€‘json)\n",
    "# - Auto-detects brand columns (b1â€¦b67, b98/b99)\n",
    "# - Built-in row-level QC checks\n",
    "# - Optional custom rules via rules.json (from Rule Builder)\n",
    "# - Optional last_wave/client_sample inputs are accepted but only used for simple notes\n",
    "\n",
    "import re\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import json\n",
    "\n",
    "st.set_page_config(page_title=\"BCS Survey Logic Checker (Mapped)\", layout=\"wide\")\n",
    "st.title(\"ðŸ“Š BCS Survey Logic Checker â€” mapped to schema\")\n",
    "st.caption(\"Auto-detect brand columns (b1â€¦b67, b98/b99), run row-level logic, and export flags. Optional custom rules JSON.\")\n",
    "\n",
    "# ----------------------------\n",
    "# File uploads\n",
    "# ----------------------------\n",
    "with st.sidebar:\n",
    "    st.header(\"Inputs\")\n",
    "    data_file = st.file_uploader(\"Current wave data (CSV)\", type=[\"csv\"]) \n",
    "    last_wave = st.file_uploader(\"Last wave (optional)\", type=[\"csv\"]) \n",
    "    client_sample = st.file_uploader(\"Client sample (optional)\", type=[\"csv\"]) \n",
    "    rules_file = st.file_uploader(\"Optional: custom rules JSON\", type=[\"json\"]) \n",
    "    rules = json.load(rules_file) if rules_file else None\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Thresholds\")\n",
    "    a1a_cap = st.slider(\"Max #brands in unaided awareness (A1a)\", 3, 25, 8)\n",
    "    close_min = st.slider(\"C-close minimum when intent is strong\", 5, 10, 8)\n",
    "    cfunc_hi = st.slider(\"Cfunc (performance) 'high' when B2 is low\", 4, 10, 6)\n",
    "\n",
    "if not data_file:\n",
    "    st.info(\"Upload the current wave CSV to begin.\")\n",
    "    st.stop()\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_file)\n",
    "except Exception as e:\n",
    "    st.error(f\"Failed to read CSV: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "prev_df = pd.read_csv(last_wave) if last_wave else None\n",
    "client_df = pd.read_csv(client_sample) if client_sample else None\n",
    "\n",
    "res = df.copy()\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers & mappings (from your schema)\n",
    "# ----------------------------\n",
    "PREFIX = {\n",
    "    \"awareness\": \"unaided_aware_\",      # A1a multi (0/1)\n",
    "    \"usage\": \"usage_\",                  # A2a multi (0/1)\n",
    "    \"impression\": \"overall_impression_\",# B2 1â€“5\n",
    "    \"consider\": \"consideration_\",       # B3a multi (0/1)\n",
    "    \"close\": \"closeness_\",              # C-close 1â€“10\n",
    "    \"cfunc\": \"performance_\",            # Cfunc 1â€“10 in this study\n",
    "}\n",
    "\n",
    "COL = {\n",
    "    \"main_brand\": \"main_brand\",                 # A2b (preferred of A2a)\n",
    "    \"pref_future_single\": \"preference\",         # B3b single pick (code/bXX/label)\n",
    "    \"E1_overall\": \"overall_satisfaction\",      # E1 (1â€“5)\n",
    "    \"E4_choose_brand\": \"likelihood_choose_brand\",  # E4 (1â€“5)\n",
    "    \"E4c_pref_strength\": \"preference_strength\",    # E4c (1â€“5)\n",
    "}\n",
    "\n",
    "S = {\n",
    "    \"HD_count\": \"n_heavy_duty_trucks\",   # S3\n",
    "    \"MD_count\": \"n_medium_duty_trucks\",  # S3b\n",
    "    \"Tractors\": \"n_tractors\",            # S3a1 (Korea)\n",
    "    \"Rigids\": \"n_rigids\",                # S3a2 (Korea)\n",
    "    \"Tippers\": \"n_tippers\",              # S3a3 (Korea)\n",
    "    \"LastPurchaseHD_cat\": \"last_purchase_hdt\",   # S4a1 coded 1..9\n",
    "    \"LastPurchaseMD_cat\": \"last_purchase_mdt\",   # S4a2 coded 1..9\n",
    "    \"Segment\": \"segment\",\n",
    "    \"OperationRange\": \"operation_range_volvo_hdt\",\n",
    "}\n",
    "\n",
    "IDCOLS = [c for c in [\"respid\", \"id\"] if c in df.columns]\n",
    "\n",
    "BRAND_SUFFIX_RE = re.compile(r\"_b(?P<brand>\\d+)$\", re.IGNORECASE)\n",
    "\n",
    "# Discover brands present for each block\n",
    "brand_cols: Dict[str, Dict[str, str]] = {blk: {} for blk in PREFIX}\n",
    "for c in df.columns:\n",
    "    for blk, pre in PREFIX.items():\n",
    "        if c.startswith(pre):\n",
    "            m = BRAND_SUFFIX_RE.search(c)\n",
    "            if m:\n",
    "                brand_cols[blk][m.group(\"brand\")] = c\n",
    "\n",
    "brands: Set[str] = set().union(*[set(d.keys()) for d in brand_cols.values()])\n",
    "getb = lambda mapping, b: mapping.get(str(b))\n",
    "\n",
    "# Brand name â†” code map (from MASTER BRAND LIST you provided)\n",
    "BRAND_NAME_TO_CODE = {\n",
    "    \"ashok leyland\": \"1\",\n",
    "    \"asia motor works\": \"2\",\n",
    "    \"beijing auto/baic/beiqi futian\": \"3\",\n",
    "    \"chevrolet\": \"4\",\n",
    "    \"cnhtc/steyr\": \"5\",\n",
    "    \"tata / tata daewoo\": \"6\",\n",
    "    \"daf\": \"7\",\n",
    "    \"dongfeng\": \"8\",\n",
    "    \"eicher\": \"9\",\n",
    "    \"erf\": \"10\",\n",
    "    \"foden\": \"11\",\n",
    "    \"force motors\": \"12\",\n",
    "    \"ford\": \"13\",\n",
    "    \"freightliner\": \"14\",\n",
    "    \"hino\": \"15\",\n",
    "    \"hongyan/sichuan auto/saic\": \"16\",\n",
    "    \"hyundai\": \"17\",\n",
    "    \"international\": \"18\",\n",
    "    \"isuzu\": \"19\",\n",
    "    \"iveco\": \"20\",\n",
    "    \"jie fang/faw\": \"21\",\n",
    "    \"kenworth\": \"22\",\n",
    "    \"mack\": \"23\",\n",
    "    \"mahindra\": \"24\",\n",
    "    \"man\": \"25\",\n",
    "    \"mercedes benz\": \"26\",\n",
    "    \"fuso\": \"27\",\n",
    "    \"ud trucks\": \"28\",\n",
    "    \"norinco\": \"29\",\n",
    "    \"peterbilt\": \"30\",\n",
    "    \"renault trucks\": \"31\",\n",
    "    \"scania\": \"32\",\n",
    "    \"sterling\": \"33\",\n",
    "    \"tata motors\": \"34\",\n",
    "    \"tatra\": \"35\",\n",
    "    \"western star\": \"36\",\n",
    "    \"volkswagen\": \"37\",\n",
    "    \"volvo\": \"38\",\n",
    "    \"yan an/shaanxi auto\": \"39\",\n",
    "    \"swaraj mazda limited\": \"40\",\n",
    "    \"bharat benz\": \"41\",\n",
    "    \"nissan diesel\": \"42\",\n",
    "    \"cat\": \"43\",\n",
    "    \"dennis eagle\": \"44\",\n",
    "    \"jac\": \"45\",\n",
    "    \"camc\": \"46\",\n",
    "    \"foton\": \"47\",\n",
    "    \"sinotruck / sitrak\": \"48\",\n",
    "    \"sany\": \"49\",\n",
    "    \"shacman\": \"50\",\n",
    "    \"powerland\": \"51\",\n",
    "    \"powerstar\": \"52\",\n",
    "    \"howo\": \"53\",\n",
    "    \"hitachi\": \"54\",\n",
    "    \"quester\": \"55\",\n",
    "    \"lgmg\": \"56\",\n",
    "    \"liugong\": \"57\",\n",
    "    \"other\": \"98\",\n",
    "}\n",
    "\n",
    "# Helpers\n",
    "\n",
    "def boolish(x) -> bool:\n",
    "    s = str(x).strip().lower()\n",
    "    return s in {\"1\", \"true\", \"t\", \"yes\", \"y\"}\n",
    "\n",
    "\n",
    "def in_vals(x, allowed: List[int]) -> bool:\n",
    "    try:\n",
    "        return int(float(x)) in allowed\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def to_num(x):\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def parse_brand_id(val) -> str | None:\n",
    "    \"\"\"Return brand code as string (e.g., '38') from code like 38 / 'b38',\n",
    "    or from label names using BRAND_NAME_TO_CODE (case-insensitive).\"\"\"\n",
    "    s = str(val).strip()\n",
    "    if not s or s.lower() in {\"nan\", \"none\"}:\n",
    "        return None\n",
    "    if s.isdigit():\n",
    "        return s\n",
    "    sl = s.lower()\n",
    "    m = re.search(r\"b(\\d+)$\", sl)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    if sl in BRAND_NAME_TO_CODE:\n",
    "        return BRAND_NAME_TO_CODE[sl]\n",
    "    sl2 = re.sub(r\"\\s+\", \" \", sl.replace(\"-\", \" \").replace(\"/\", \"/\"))\n",
    "    return BRAND_NAME_TO_CODE.get(sl2)\n",
    "\n",
    "# ----- Custom rules loader & applier (from Rule Builder) -----\n",
    "\n",
    "def apply_custom_rules(df: pd.DataFrame, res: pd.DataFrame, rules: dict | None) -> pd.DataFrame:\n",
    "    \"\"\"Apply generic custom rules exported from Rule Builder to augment built-in checks.\n",
    "    Supported types:\n",
    "      - equals: {\"cols\":[\"A\",\"B\"]}\n",
    "      - implies_values: if Xâˆˆ{â€¦} â‡’ Yâˆˆ{â€¦}\n",
    "      - brand_consider_implies_impression: auto-iterate across brand ids for prefixes\n",
    "    \"\"\"\n",
    "    if not rules:\n",
    "        return res\n",
    "    for r in rules.get(\"rules\", []):\n",
    "        t = r.get(\"type\")\n",
    "        name = r.get(\"name\") or f\"CHK_{t}\"\n",
    "        msg = r.get(\"message\", \"Violation\")\n",
    "\n",
    "        # 1) Column equality\n",
    "        if t == \"equals\":\n",
    "            a, b = r.get(\"cols\", [None, None])\n",
    "            if a in df.columns and b in df.columns:\n",
    "                bad = df[a].astype(str) != df[b].astype(str)\n",
    "                res.loc[bad, name] = msg\n",
    "                res.loc[~bad, name] = \"OK\"\n",
    "\n",
    "        # 2) If X in {...} then Y in {allowed}\n",
    "        elif t == \"implies_values\":\n",
    "            cond_col = r.get(\"if\", {}).get(\"col\")\n",
    "            then_col = r.get(\"then\", {}).get(\"col\")\n",
    "            cond_vals = r.get(\"if\", {}).get(\"in\", [])\n",
    "            allow_vals = r.get(\"then\", {}).get(\"allowed\", [])\n",
    "            if cond_col in df.columns and then_col in df.columns:\n",
    "                cond = df[cond_col].isin(cond_vals)\n",
    "                bad = cond & ~df[then_col].isin(allow_vals)\n",
    "                res.loc[bad, name] = msg\n",
    "                res.loc[cond & ~bad, name] = \"OK\"\n",
    "\n",
    "        # 3) Brand pattern rule\n",
    "        elif t == \"brand_consider_implies_impression\":\n",
    "            consider_prefix = r.get(\"consider_prefix\", \"consideration_\")\n",
    "            impression_prefix = r.get(\"impression_prefix\", \"overall_impression_\")\n",
    "            allowed = r.get(\"allowed\", [4, 5])\n",
    "            for col in df.columns:\n",
    "                if not col.startswith(consider_prefix):\n",
    "                    continue\n",
    "                m = re.search(r\"_b(\\d+)$\", col)\n",
    "                if not m:\n",
    "                    continue\n",
    "                bid = m.group(1)\n",
    "                tgt = f\"{impression_prefix}b{bid}\"\n",
    "                if tgt not in df.columns:\n",
    "                    continue\n",
    "                bad = (to_num(df[col]) == 1) & ~to_num(df[tgt]).isin(allowed)\n",
    "                res.loc[bad, f\"{name}_b{bid}\"] = msg\n",
    "                res.loc[(to_num(df[col]) == 1) & ~bad, f\"{name}_b{bid}\"] = \"OK\"\n",
    "    return res\n",
    "\n",
    "# ----------------------------\n",
    "# Core checks\n",
    "# ----------------------------\n",
    "# 0) Structural: S3a1-3 sum equals S3 (if columns exist)\n",
    "if all(k in df.columns for k in [S[\"HD_count\"], S[\"Tractors\"], S[\"Rigids\"], S[\"Tippers\"]]):\n",
    "    subsum = to_num(df[S[\"Tractors\"]]).fillna(0) + to_num(df[S[\"Rigids\"]]).fillna(0) + to_num(df[S[\"Tippers\"]]).fillna(0)\n",
    "    total = to_num(df[S[\"HD_count\"]])\n",
    "    res.loc[(total.notna()) & (subsum != total), \"CHK_S3a_sum\"] = \"S3a1-3 â‰  S3\"\n",
    "    res.loc[res[\"CHK_S3a_sum\"].isna(), \"CHK_S3a_sum\"] = \"OK\"\n",
    "\n",
    "# 3) A1a total sanity (awareness) + cap\n",
    "aw_cols = list(brand_cols[\"awareness\"].values())\n",
    "if aw_cols:\n",
    "    sel = df[aw_cols].applymap(boolish)\n",
    "    count_aw = sel.sum(axis=1)\n",
    "    res[\"CHK_A1a_total_count\"] = count_aw\n",
    "    res.loc[count_aw > a1a_cap, \"CHK_A1a_total_flag\"] = f\">{a1a_cap} brands\"\n",
    "    res.loc[count_aw <= a1a_cap, \"CHK_A1a_total_flag\"] = \"OK\"\n",
    "\n",
    "# 4) Main make (A2b) must be in A1a **and** A2a\n",
    "if COL[\"main_brand\"] in df.columns:\n",
    "    mb = df[COL[\"main_brand\"]].apply(parse_brand_id)\n",
    "    ok_aw, ok_us = [], []\n",
    "    for i, b in mb.items():\n",
    "        if b is None:\n",
    "            ok_aw.append(True); ok_us.append(True); continue\n",
    "        a1col = getb(brand_cols[\"awareness\"], b)\n",
    "        ucol = getb(brand_cols[\"usage\"], b)\n",
    "        ok_aw.append(True if a1col is None else boolish(df.at[i, a1col]))\n",
    "        ok_us.append(True if ucol is None else boolish(df.at[i, ucol]))\n",
    "    ok_aw = pd.Series(ok_aw, index=df.index)\n",
    "    ok_us = pd.Series(ok_us, index=df.index)\n",
    "    res.loc[~ok_aw, \"CHK_A2b_in_A1a\"] = \"Main brand not in A1a\"\n",
    "    res[\"CHK_A2b_in_A1a\"] = res[\"CHK_A2b_in_A1a\"].fillna(\"OK\")\n",
    "    res.loc[~ok_us, \"CHK_A2b_in_A2a\"] = \"Main brand not in A2a\"\n",
    "    res[\"CHK_A2b_in_A2a\"] = res[\"CHK_A2b_in_A2a\"].fillna(\"OK\")\n",
    "\n",
    "# 7) If a brand is used (A2a), B2 overall impression should be 4/5\n",
    "if brand_cols[\"usage\"] and brand_cols[\"impression\"]:\n",
    "    for b in brands:\n",
    "        ucol = getb(brand_cols[\"usage\"], b)\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not ucol or not icol:\n",
    "            continue\n",
    "        used = df[ucol].apply(boolish)\n",
    "        bad = used & ~df[icol].apply(lambda x: in_vals(x, [4, 5]))\n",
    "        res.loc[bad, f\"CHK_B2_for_used_b{b}\"] = \"B2 should be 4/5\"\n",
    "\n",
    "# 8) If considering (B3a), B2 should be 4/5\n",
    "if brand_cols[\"consider\"] and brand_cols[\"impression\"]:\n",
    "    for b in brands:\n",
    "        ccol = getb(brand_cols[\"consider\"], b)\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not ccol or not icol:\n",
    "            continue\n",
    "        cons = df[ccol].apply(boolish)\n",
    "        bad = cons & ~df[icol].apply(lambda x: in_vals(x, [4, 5]))\n",
    "        res.loc[bad, f\"CHK_B2_for_consider_b{b}\"] = \"B2 should be 4/5\"\n",
    "\n",
    "# 9) If preferred for next purchase (B3b single), B2 for that brand should be 4/5\n",
    "if COL[\"pref_future_single\"] in df.columns and brand_cols[\"impression\"]:\n",
    "    pref = df[COL[\"pref_future_single\"]].apply(parse_brand_id)\n",
    "    for idx, b in pref.items():\n",
    "        if b is None:\n",
    "            continue\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not icol:\n",
    "            continue\n",
    "        if not in_vals(df.at[idx, icol], [4, 5]):\n",
    "            res.loc[idx, f\"CHK_B2_for_pref_b{b}\"] = \"B2 should be 4/5 for preferred brand\"\n",
    "\n",
    "# 10) C-close high when strong intent/impression\n",
    "if brand_cols[\"close\"]:\n",
    "    for b in brands:\n",
    "        ccol = getb(brand_cols[\"close\"], b)\n",
    "        if not ccol:\n",
    "            continue\n",
    "        strong = pd.Series(False, index=df.index)\n",
    "        if brand_cols[\"consider\"].get(b):\n",
    "            strong |= df[brand_cols[\"consider\"][b]].apply(boolish)\n",
    "        if brand_cols[\"impression\"].get(b):\n",
    "            strong |= df[brand_cols[\"impression\"][b]].apply(lambda x: in_vals(x, [4, 5]))\n",
    "        bad = strong & ~df[ccol].apply(lambda x: in_vals(x, list(range(close_min, 11))))\n",
    "        res.loc[bad, f\"CHK_Cclose_high_b{b}\"] = f\"Expect â‰¥{close_min}\"\n",
    "\n",
    "# 11) Cfunc vs B2 alignment (avoid high cfunc when B2 low)\n",
    "if brand_cols[\"cfunc\"] and brand_cols[\"impression\"]:\n",
    "    for b in brands:\n",
    "        cf = getb(brand_cols[\"cfunc\"], b)\n",
    "        icol = getb(brand_cols[\"impression\"], b)\n",
    "        if not cf or not icol:\n",
    "            continue\n",
    "        def misaligned(r):\n",
    "            b2v = to_num(r[icol])\n",
    "            cfv = to_num(r[cf])\n",
    "            if pd.isna(b2v) or pd.isna(cfv):\n",
    "                return False\n",
    "            return (b2v < 4) and (cfv >= cfunc_hi)\n",
    "        bad = df.apply(misaligned, axis=1)\n",
    "        res.loc[bad, f\"CHK_Cfunc_vs_B2_b{b}\"] = \"Misaligned\"\n",
    "\n",
    "# 23) Straight-liners: truck_rating_*, salesdelivery_rating_*, workshop_rating_*\n",
    "for pre in [\"truck_rating_\", \"salesdelivery_rating_\", \"workshop_rating_\"]:\n",
    "    cols = [c for c in df.columns if c.startswith(pre)]\n",
    "    if cols:\n",
    "        vals = df[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        straight = vals.nunique(axis=1) == 1\n",
    "        res.loc[straight, f\"CHK_{pre}straightliner\"] = \"Straight-liner\"\n",
    "\n",
    "# 24) If brand(s) considered but E4 low â†’ flag (coarse sanity)\n",
    "if COL[\"E4_choose_brand\"] in df.columns and brand_cols[\"consider\"]:\n",
    "    low_e4 = ~df[COL[\"E4_choose_brand\"]].apply(lambda x: in_vals(x, [4, 5]))\n",
    "    any_consider = pd.DataFrame({b: df[col].apply(boolish) for b, col in brand_cols[\"consider\"].items()}).any(axis=1) if brand_cols[\"consider\"] else False\n",
    "    res.loc[any_consider & low_e4, \"CHK_E4_low_with_consider\"] = \"Low E4 but considering brands\"\n",
    "\n",
    "# 37) E1 vs F1 proximity (|diff|<=2)\n",
    "if COL[\"E1_overall\"] in df.columns and \"overall_rating_truck\" in df.columns:\n",
    "    e1 = to_num(df[COL[\"E1_overall\"]])\n",
    "    f1 = to_num(df[\"overall_rating_truck\"])\n",
    "    res.loc[(e1 - f1).abs() > 2, \"CHK_E1_vs_F1\"] = \">2 pts diff\"\n",
    "    res[\"CHK_E1_vs_F1\"] = res[\"CHK_E1_vs_F1\"].fillna(\"OK\")\n",
    "\n",
    "# 5/16) Last purchase vs A3 brand purchase recency (per-brand years-ago fields)\n",
    "A3_pre = \"last_purchase_b\"        # years ago (0..99 where 99=never)\n",
    "A4_pre = \"last_workshop_visit_b\"  # years ago (0..99/never)\n",
    "A4b_pre = \"last_workshop2_visit_b\"\n",
    "\n",
    "def find_yearago_block(prefix: str) -> Dict[str, str]:\n",
    "    m: Dict[str, str] = {}\n",
    "    for c in df.columns:\n",
    "        if c.startswith(prefix):\n",
    "            mm = BRAND_SUFFIX_RE.search(c)\n",
    "            if mm:\n",
    "                m[mm.group(\"brand\")] = c\n",
    "    return m\n",
    "\n",
    "A3 = find_yearago_block(A3_pre)\n",
    "A4 = find_yearago_block(A4_pre)\n",
    "A4b = find_yearago_block(A4b_pre)\n",
    "\n",
    "# If S4a1 says a new HD truck within last N categories (1..6 â‰ˆ 2020â€“2025), then at least one brand should have A3 <= ~5 years\n",
    "if S[\"LastPurchaseHD_cat\"] in df.columns and A3:\n",
    "    recent_hd = df[S[\"LastPurchaseHD_cat\"]].apply(lambda x: in_vals(x, [1,2,3,4,5,6]))\n",
    "    any_recent_brand = pd.DataFrame({b: to_num(df[c]) for b, c in A3.items()}) <= 5\n",
    "    has_recent = any_recent_brand.any(axis=1)\n",
    "    res.loc[recent_hd & ~has_recent, \"CHK_S4a1_vs_A3\"] = \"No brand with purchase â‰¤5y despite S4a1 recent\"\n",
    "\n",
    "# Usage but never used authorised workshop (A4 = 99)\n",
    "if A4 and brand_cols[\"usage\"]:\n",
    "    for b in brands:\n",
    "        ucol = getb(brand_cols[\"usage\"], b)\n",
    "        wcol = A4.get(b)\n",
    "        if not ucol or not wcol:\n",
    "            continue\n",
    "        used = df[ucol].apply(boolish)\n",
    "        never_ws = to_num(df[wcol]) == 99\n",
    "        res.loc[used & never_ws, f\"CHK_A4_never_b{b}\"] = \"Used brand but never used workshop\"\n",
    "\n",
    "# ----------------------------\n",
    "# Cross-wave summaries (notes only, if last_wave uploaded)\n",
    "# ----------------------------\n",
    "notes = []\n",
    "if prev_df is not None:\n",
    "    try:\n",
    "        aw_prev = {m.group(\"brand\"): col for col in prev_df.columns for m in [BRAND_SUFFIX_RE.search(col)] if col.startswith(PREFIX[\"awareness\"]) and m}\n",
    "        us_prev = {m.group(\"brand\"): col for col in prev_df.columns for m in [BRAND_SUFFIX_RE.search(col)] if col.startswith(PREFIX[\"usage\"]) and m}\n",
    "        rates = []\n",
    "        for b, u in us_prev.items():\n",
    "            a = aw_prev.get(b)\n",
    "            if not a:\n",
    "                continue\n",
    "            r = ((~prev_df[a].apply(boolish)) & prev_df[u].apply(boolish)).mean()\n",
    "            rates.append(r)\n",
    "        if rates:\n",
    "            notes.append(f\"Last wave A2a-not-in-A1a avg: {np.mean(rates):.1%}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ----------------------------\n",
    "# Apply optional custom rules JSON (if provided)\n",
    "# ----------------------------\n",
    "try:\n",
    "    res = apply_custom_rules(df, res, rules)\n",
    "except Exception:\n",
    "    st.warning(\"Custom rules JSON present but could not be applied. Check the Rule Builder export.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Output\n",
    "# ----------------------------\n",
    "st.subheader(\"Results preview\")\n",
    "st.dataframe(res, use_container_width=True)\n",
    "\n",
    "csv = res.to_csv(index=False).encode(\"utf-8\")\n",
    "st.download_button(\"ðŸ’¾ Download flagged CSV\", csv, file_name=\"bcs_checked_mapped.csv\", mime=\"text/csv\")\n",
    "\n",
    "if notes:\n",
    "    st.info(\"\\n\".join(notes))\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"**Built-ins:** S3a sum to S3; A1a cap; A2bâˆˆA1a & âˆˆA2a; usage/considerâ†’B2â‰¥4; pref(B3b)â†’B2â‰¥4; strong intentâ†’C-closeâ‰¥min; Cfunc vs B2; straight-liners (F2/F4/F6); B3aÃ—E4 sanity; E1 vs F1 proximity; S4a1 recent vs A3; usage but never workshop. **+ Optional custom rules JSON.**\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
